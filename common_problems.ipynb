{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7560b931-d40f-4397-8614-0f725428a6b5",
   "metadata": {},
   "source": [
    "# Load \n",
    "Loading data and removing whitespace from header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14321c59-75c7-451e-8487-5f2e2cdc0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "samples = spark.read.csv(\n",
    "    os.path.expanduser(\"~/data/DataSample.csv\"),\n",
    "    header=True,\n",
    "    sep=\",\",\n",
    "    inferSchema=\"True\",\n",
    ")\n",
    "points = spark.read.csv(\n",
    "    os.path.expanduser(\"~/data/POIList.csv\"), header=True, sep=\",\", inferSchema=\"True\"\n",
    ")\n",
    "# removing excess whitespace in headers\n",
    "for each in samples.schema.names:\n",
    "    samples = samples.withColumnRenamed(each, each.strip())\n",
    "for each in points.schema.names:\n",
    "    points = points.withColumnRenamed(each, each.strip())\n",
    "samples = samples.withColumn(\"TimeSt\", F.to_timestamp(\"TimeSt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aee30d4-ceab-4f44-b718-abdea1338e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+-------+--------+---------+--------+---------+\n",
      "|_ID    |TimeSt                 |Country|Province|City     |Latitude|Longitude|\n",
      "+-------+-----------------------+-------+--------+---------+--------+---------+\n",
      "|4516516|2017-06-21 00:00:00.143|CA     |ON      |Waterloo |43.49347|-80.49123|\n",
      "|4516547|2017-06-21 18:00:00.193|CA     |ON      |London   |42.9399 |-81.2709 |\n",
      "|4516550|2017-06-21 15:00:00.287|CA     |ON      |Guelph   |43.5776 |-80.2201 |\n",
      "|4516600|2017-06-21 15:00:00.307|CA     |ON      |Stratford|43.3716 |-80.9773 |\n",
      "|4516613|2017-06-21 15:00:00.497|CA     |ON      |Stratford|43.3716 |-80.9773 |\n",
      "+-------+-----------------------+-------+--------+---------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+---------+-----------+\n",
      "|POIID|Latitude |Longitude  |\n",
      "+-----+---------+-----------+\n",
      "|POI1 |53.546167|-113.485734|\n",
      "|POI2 |53.546167|-113.485734|\n",
      "|POI3 |45.521629|-73.566024 |\n",
      "|POI4 |45.22483 |-63.232729 |\n",
      "+-----+---------+-----------+\n",
      "\n",
      "There are 22025 rows in DataSample.csv\n",
      "There are 4 rows in the cleaned POIList.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('_ID', 'int'),\n",
       "  ('TimeSt', 'timestamp'),\n",
       "  ('Country', 'string'),\n",
       "  ('Province', 'string'),\n",
       "  ('City', 'string'),\n",
       "  ('Latitude', 'double'),\n",
       "  ('Longitude', 'double')],\n",
       " [('POIID', 'string'), ('Latitude', 'double'), ('Longitude', 'double')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.show(5, truncate=False)\n",
    "points.show(truncate=False)\n",
    "print(f\"There are {samples.count()} rows in DataSample.csv\")\n",
    "print(f\"There are {points.count()} rows in the POIList.csv\")\n",
    "samples.dtypes, points.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2cf638-2262-467c-ab88-137af7b57ea8",
   "metadata": {},
   "source": [
    "# 1. Cleanup\n",
    "\n",
    "Find the sample dataset of request logs in `data/DataSample.csv`. We consider records with identical `geoinfo` and `timest` as suspicious. Please clean up the sample dataset by filtering out those questionable request records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01967882",
   "metadata": {},
   "source": [
    "# Q1 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700ce9f7-9c3e-43d4-b344-057fbe516116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17973 rows in the cleaned DataSample.csv\n",
      "There are 2 rows in the cleaned POIList.csv\n"
     ]
    }
   ],
   "source": [
    "# removing all of the duplicated request\n",
    "samples = samples.join(\n",
    "    samples.groupBy(\"Latitude\", \"Longitude\", \"TimeSt\")\n",
    "    .count()\n",
    "    .where(\"count=1\")\n",
    "    .drop(\"count\"),\n",
    "    on=[\"Latitude\", \"Longitude\", \"TimeSt\"],\n",
    ")\n",
    "# points = points.join(\n",
    "#     points.groupBy(\"Latitude\", \"Longitude\").count().where(\"count=1\").drop(\"count\"),\n",
    "#     on=[\"Latitude\", \"Longitude\"],\n",
    "# )\n",
    "print(f\"There are {samples.count()} rows in the cleaned DataSample.csv\")\n",
    "# print(f\"There are {points.count()} rows in the cleaned POIList.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615057c-9f92-484d-b061-270b636b27fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Label\n",
    "\n",
    "Assign each *request* (from `data/DataSample.csv`) to the closest (i.e., minimum distance) *POI* (from `data/POIList.csv`).\n",
    "\n",
    "Note: a *POI* is a geographical Point of Interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2f2f2-5813-4499-b9a1-59b4772ca77e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notes\n",
    "\n",
    "- Need to convert coordinates to radians and use angular distance because the earth isnt flat...\n",
    "\n",
    "### haversine\n",
    "$$d=\\theta r$$ \n",
    "Where **d** is the arc length of the corresponding angle $\\theta$ of sphere with radius **r**\n",
    "Can compute **d** by computing $hav(\\theta)$, which can be computed as the difference of the longitude and latitude of two points defining the arc.\n",
    "\n",
    "With $$\\begin{aligned} h&=hav(\\theta) \\\\\n",
    "&=\\sin^2{\\frac{\\theta}{2}}\\\\\n",
    "&=\\frac{1-\\cos{\\theta}}{2}\\\\\n",
    "&=hav(\\phi_2-\\phi_1)+(1-hav(\\phi_1-\\phi_2)-hav(\\phi_1+\\phi_2))\\cdot hav(\\lambda_2-\\lambda_1) \\end{aligned}$$\n",
    "\n",
    "Where $\\phi$ is the latitude and $\\lambda$ is the longitude\n",
    "\n",
    "Solving for **d**:\n",
    "$$\\begin{aligned} d&=2r\\arcsin{\\sqrt{h}} \\\\\n",
    "&= 2r\\arcsin{\\sqrt{\\sin^2{\\frac{\\phi_2-\\phi_1}{2}}+\\cos{\\phi_1}\\cdot\\cos{\\phi_2}\\cdot\\sin^2{\\frac{\\lambda_2-\\lambda_1}{2}}}} \\end{aligned}$$\n",
    "\n",
    "- Answers have errors that are no better than 0.5% due to variation of earth's radius (needed citation)\n",
    "- $h\\in [0,1]$ for $d\\in \\mathbb{R}$\n",
    "- R=6371 KM\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import DistanceMetric\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dist = DistanceMetric.get_metric('haversine')\n",
    "def closest_point(point, points):\n",
    "    \"\"\" Find closest point from a list of points. \"\"\"\n",
    "    return points[dist.pairwise([point], points).argmin()]\n",
    "\n",
    "ds['point'] = [(x, y) for x,y in zip(np.radians(ds['Latitude']), np.radians(ds['Longitude']))]\n",
    "poi['point'] = [(x, y) for x,y in zip(np.radians(poi['Latitude']), np.radians(poi['Longitude']))]\n",
    "ds['closest'] = [closest_point(x, list(poi['point'])) for x in ds['point']]\n",
    "ds = ds.merge(poi[['POIID', 'point']].round(4), how='left', validate = 'm:1',\n",
    "         left_on='closest', right_on='point').drop(['closest', 'point_x', 'point_y'], axis=1)\n",
    "```\n",
    "\n",
    "Pandas implementation relatively easy, need to figure out how to implement in spark without looping over the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e9cf4",
   "metadata": {},
   "source": [
    "# Q2 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c75f6a-afa6-4869-9201-d83452be6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "points.createOrReplaceTempView(\"points\")\n",
    "samples.createOrReplaceTempView(\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd558bc7-786c-4790-a5c7-bcdcc1af6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to calculate distance, uses crossjoin..\n",
    "query = \"\"\"\n",
    "SELECT _ID,\n",
    "        TimeSt,\n",
    "        Country,\n",
    "        Province,\n",
    "        City,\n",
    "        s.Latitude,\n",
    "        s.Longitude,\n",
    "        p.POIID,\n",
    "        2 * 6371 * ASIN(SQRT(POW(SIN((RADIANS(p.Latitude)-RADIANS(s.Latitude)) * 0.5), 2)\n",
    "            +COS(RADIANS(s.Latitude))*COS(RADIANS(p.Latitude))\n",
    "            *POW(SIN((RADIANS(p.Longitude)-RADIANS(s.Longitude)) * 0.5),2))) as distance_km\n",
    "FROM samples s CROSS JOIN \n",
    "(\n",
    "SELECT  POIID,\n",
    "        Latitude,\n",
    "        Longitude\n",
    "FROM points) AS p ON 1=1\n",
    "ORDER BY s._ID\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77028508-2a7a-4f87-bce9-1b0094c950cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance and store in new dataframe\n",
    "df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736a2b49-869f-4c30-b1a3-adc32ab91f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group request from same location and order them by distance (descending)\n",
    "# assign row number and show only the first (closest) POIID\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = Window.partitionBy([\"_ID\", \"Latitude\", \"Longitude\"]).orderBy(\"distance_km\")\n",
    "df_shortest = (\n",
    "    df.withColumn(\"rn\", F.row_number().over(w))\n",
    "    .where(F.col(\"rn\") == 1)\n",
    "    .drop(\"rn\")\n",
    "    .orderBy(\"_ID\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47845d4a-77a0-41d4-8caa-b2394b829243",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_shortest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22824\\1737614489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_shortest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_shortest' is not defined"
     ]
    }
   ],
   "source": [
    "df_shortest.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ca154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write assigned requests to new file\n",
    "df_shortest.write.csv(\n",
    "    os.path.expanduser(\"~/data/DataSample_Assigned.csv\"),\n",
    "    header=True,\n",
    "    sep=\",\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df6f1c2-c1a0-412c-bb69-3bdd740a7faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------\n",
      " Latitude  | 43.3716                 \n",
      " Longitude | -80.9773                \n",
      " TimeSt    | 2017-06-21 15:00:00.307 \n",
      " _ID       | 4516600                 \n",
      " Country   | CA                      \n",
      " Province  | ON                      \n",
      " City      | Stratford               \n",
      "-RECORD 1----------------------------\n",
      " Latitude  | 43.3716                 \n",
      " Longitude | -80.9773                \n",
      " TimeSt    | 2017-06-21 15:00:00.497 \n",
      " _ID       | 4516613                 \n",
      " Country   | CA                      \n",
      " Province  | ON                      \n",
      " City      | Stratford               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Not going to consider the milisec difference in timestamp as suspicious\n",
    "# since 12 other requests were made during that time\n",
    "t = spark.sql(\n",
    "    \"\"\" \n",
    "SELECT * \n",
    "FROM samples\n",
    "WHERE _ID=4516600 OR _ID=4516613\n",
    "\"\"\"\n",
    ")\n",
    "t.show(truncate=False, vertical=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('qc_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f25c5754f634a75bc1e9c6f5e67b771d176e3ee411e5750061be905c38808269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
